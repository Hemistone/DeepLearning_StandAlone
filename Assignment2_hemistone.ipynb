{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment2_hemistone.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/heartcored98/Standalone-DeepLearning/blob/master/Lec3/Lab4_write_pretty_DL_code.ipynb","timestamp":1548572787920}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"uRVlZq75JUJn","colab_type":"code","outputId":"ab7ea633-6eb2-4700-83c1-c24b8658132f","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1548573035539,"user_tz":-540,"elapsed":14750,"user":{"displayName":"황반석","photoUrl":"","userId":"02138940222900352760"}}},"cell_type":"code","source":["!pip install -q torch==1.0.0 torchvision\n","import torch\n","print(torch.__version__)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["1.0.0\n"],"name":"stdout"}]},{"metadata":{"id":"PD4cIKKvKFCC","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import argparse\n","import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"29UainWPco7Y","colab_type":"text"},"cell_type":"markdown","source":["## Data Preparation"]},{"metadata":{"id":"Cu753dPPKGkV","colab_type":"code","outputId":"6c62d639-b256-4a0d-edfc-35b1a0d00c6b","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1548573079833,"user_tz":-540,"elapsed":31882,"user":{"displayName":"황반석","photoUrl":"","userId":"02138940222900352760"}}},"cell_type":"code","source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","trainset, valset = torch.utils.data.random_split(trainset, [40000, 10000])\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n","                                          shuffle=True, num_workers=2)\n","valloader = torch.utils.data.DataLoader(valset, batch_size=4, \n","                                        shuffle=False)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n","                                         shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"metadata":{"id":"RxnfFJwBcsAv","colab_type":"text"},"cell_type":"markdown","source":["## Model Architecture"]},{"metadata":{"id":"_G6bZbbkMWWt","colab_type":"code","colab":{}},"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, in_dim, out_dim, hid_dim, n_layer, act, dropout):\n","        super(MLP, self).__init__()\n","        self.in_dim = in_dim\n","        self.out_dim = out_dim\n","        self.hid_dim = hid_dim\n","        self.n_layer = n_layer\n","        self.act = act\n","        self.dropout = nn.Dropout(dropout)\n","        \n","        self.fc = nn.Linear(self.in_dim, self.hid_dim)\n","        self.linears = nn.ModuleList()\n","        \n","        for i in range(self.n_layer-1):\n","            self.linears.append(nn.Linear(self.hid_dim, self.hid_dim))\n","        self.fc2 = nn.Linear(self.hid_dim, self.out_dim)\n","        \n","        if self.act == 'relu':\n","            self.act = nn.ReLU()\n","          \n","    def forward(self, x):\n","        x = self.act(self.fc(x))\n","        for fc in self.linears:\n","            x = self.dropout(self.act(fc(x)))\n","        x = self.fc2(x)\n","        return x\n","      \n","net = MLP(3072, 10, 100, 4, 'relu', 0.1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"itGsp6jDWs_a","colab_type":"text"},"cell_type":"markdown","source":["## Define Experiment"]},{"metadata":{"id":"LiOCP6TqWw2V","colab_type":"code","colab":{}},"cell_type":"code","source":["def experiment(args):\n","  \n","    net = MLP(args.in_dim, args.out_dim, args.hid_dim, args.n_layer, args.act, args.dropout)\n","    net.cuda()\n","    print(net)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=args.mm, weight_decay = args.weight_decay)\n","    \n","    #====== Basic information collecters ======#\n","    trainLossList = [] #Collecting experiments train losses\n","    valLossList = [] #Collecting experiments validation losses\n","    valAcrList = [] #Collecting experiments validation accuracies\n","    #==========================================#\n","    \n","    for epoch in range(args.epoch):  # loop over the dataset multiple times\n","\n","        # ==== Train ===== #\n","        net.train()\n","        optimizer.zero_grad()\n","        \n","        running_loss = 0.0\n","        train_loss = 0.0\n","        for i, data in enumerate(trainloader, 0):\n","            # get the inputs\n","            inputs, labels = data\n","            inputs = inputs.view(-1, 3072)\n","            \n","            inputs = inputs.cuda()\n","            labels = labels.cuda()\n","            \n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # print statistics\n","            running_loss += loss.item()\n","            train_loss += loss.item()\n","            \n","            \"\"\"\n","            if i % 2000 == 1999:    # print every 2000 mini-batches\n","                print('[%d, %5d] loss: %.3f' %\n","                      (epoch + 1, i + 1, running_loss / 2000))\n","                running_loss = 0.0\n","            \"\"\"\n","                \n","\n","        # ==== Validation ====== #\n","        net.eval()\n","        optimizer.zero_grad()\n","        \n","        correct = 0\n","        total = 0\n","        val_loss = 0 ########\n","        with torch.no_grad():\n","            for data in valloader:\n","                images, labels = data\n","                images = images.view(-1, 3072)\n","                \n","                ################################\n","                images = images.cuda()\n","                labels = labels.cuda()\n","                \n","                outputs = net(images)\n","\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item()\n","\n","                _, predicted = torch.max(outputs.data, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","            val_loss = val_loss / len(valloader)\n","            val_acc = 100 * correct / total\n","            train_loss = train_loss / len(trainloader)\n","            \n","            trainLossList.append(train_loss)\n","            valLossList.append(val_loss)\n","            valAcrList.append(val_acc)\n","            \n","        print('Debug Log : Epoch {}, Train Loss: {}, Val Loss: {}, Val Acc: {}'.format(epoch, train_loss, val_loss, val_acc ))\n","\n","\n","    # ===== Evaluation(Test) ===== #\n","    net.eval()\n","    optimizer.zero_grad()\n","    \n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data\n","            images = images.view(-1, 3072)\n","            images = images.cuda()\n","            labels = labels.cuda()\n","\n","            outputs = net(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","        test_acc = 100 * correct / total\n","            \n","    return visualize(args, trainLossList, valLossList, valAcrList, test_acc)\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"03QgHGbpepcB","colab_type":"text"},"cell_type":"markdown","source":["##Visualization"]},{"metadata":{"id":"dJsHepTler6x","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def visualize(args, trainLossList, valLossList, valAcrList, test_acc):\n","    epoch = []\n","    for i in range(len(trainLossList)):\n","        epoch.append(i)\n","    fig = plt.figure(figsize = (10, 5))\n","    ax1 = fig.add_subplot(1, 2, 1)\n","    ax1.plot(epoch, trainLossList, label=\"train\")\n","    ax1.plot(epoch, valLossList, label=\"validation\")\n","    ax1.set_xlabel('epoch')\n","    ax1.set_ylabel('loss')\n","    \n","    ax2 = fig.add_subplot(1, 2, 2)\n","    ax2.plot(epoch, valAcrList)\n","    ax2.set_xlabel('epoch')\n","    ax2.set_ylabel('accuracy')\n","    \n","    fig.suptitle('< n_layer : {} , hid_dim : {} , dropoutRate : {}, L2 alpha : {} >   test_acc : {}%'.format(args.n_layer, args.hid_dim, args.dropout, args.weight_decay, test_acc))\n","    \n","    plt.show()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"omgExzmQgU1J","colab_type":"text"},"cell_type":"markdown","source":["## Experiment"]},{"metadata":{"id":"DRoOy_B3Wu7B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":622},"outputId":"9ef84b57-4f45-4fb1-d14a-e39cbcfaf578","executionInfo":{"status":"error","timestamp":1548604504224,"user_tz":-540,"elapsed":35985,"user":{"displayName":"황반석","photoUrl":"","userId":"02138940222900352760"}}},"cell_type":"code","source":["seed = 123\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","\n","parser = argparse.ArgumentParser()\n","args = parser.parse_args(\"\")\n","\n","\n","args.n_layer = 5\n","args.in_dim = 3072\n","args.out_dim = 10\n","args.hid_dim = 100\n","args.act = 'relu'\n","\n","args.lr = 0.001\n","args.mm = 0.9\n","args.epoch = 20\n","\n","#==additional entities===#\n","args.dropout = 0\n","args.weight_decay = 0.01\n","#========================#\n","\n","#==== variables ===#\n","list_var1 = [2] #layer number\n","list_var2 = [500] #hidden dimension\n","list_var3 = [0.1, 0.2] #dropout rate\n","list_var4 = [0.01, 0.1, 1] #L2 reg factors(alpha)\n","#==================#\n","\n","\n","for var4 in list_var4:\n","    for var3 in list_var3:\n","        for var1 in list_var1:\n","            for var2 in list_var2:\n","                args.n_layer = var1\n","                args.hid_dim = var2\n","                args.dropout = var3\n","                args.weight_decay = var4\n","                experiment(args)"],"execution_count":44,"outputs":[{"output_type":"stream","text":["MLP(\n","  (dropout): Dropout(p=0.1)\n","  (fc): Linear(in_features=3072, out_features=500, bias=True)\n","  (linears): ModuleList(\n","    (0): Linear(in_features=500, out_features=500, bias=True)\n","  )\n","  (fc2): Linear(in_features=500, out_features=10, bias=True)\n","  (act): ReLU()\n",")\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-ed9911da9e48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-40-d33fa9ce852a>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"xC98ReytBM31","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}